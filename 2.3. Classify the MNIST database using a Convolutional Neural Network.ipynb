{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the MNIST database using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* create two convolutional layers\n",
    "* create a function that flattens the output\n",
    "* use two fully connected layers connected by ReLU\n",
    "* use batch training, change the cost function accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/old.png\"> **Old Code:** Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr = data.train.images\n",
    "ytr = data.train.labels\n",
    "\n",
    "xte = data.test.images\n",
    "yte = data.test.labels\n",
    "\n",
    "xva = data.validation.images\n",
    "yva = data.validation.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/old.png\"> **Old Code:** Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(input, filter_size, in_channels, out_channels, conv_strides, pool_kernel, pool_strides):\n",
    "\n",
    "    filter_shape = [filter_size, filter_size, in_channels, out_channels]\n",
    "    biases_shape = [out_channels]\n",
    "    \n",
    "    filter = tf.Variable(tf.truncated_normal(filter_shape))\n",
    "    biases = tf.Variable(tf.truncated_normal(biases_shape))\n",
    "    \n",
    "    result = tf.nn.conv2d(input, filter, strides=conv_strides, padding='SAME') + biases\n",
    "    result = tf.nn.max_pool(value=result,ksize=pool_kernel,strides=pool_strides,padding='SAME')\n",
    "    result = tf.nn.relu(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/new.png\"> **New Code:** make a flat layer out of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(input):\n",
    "    \n",
    "    layer_shape = input.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat = tf.reshape(input, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/old.png\"> **Same fully connected layer as in 1.8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(input, num_features, num_outputs):\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([num_features, num_outputs], stddev=0.05))\n",
    "    biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "\n",
    "    output = tf.matmul(input, weights) + biases\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/modified.png\"> **Modified Code:** add batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(iterations, x_train, y_train, batch_size):\n",
    "    \n",
    "    for i in range(0,iterations):  \n",
    "        x1, x2, y1, y2 = train_test_split(x_train, y_train, train_size=batch_size, random_state=i)        \n",
    "        sess.run(train_step,feed_dict = {x: x1, y: y1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/modified.png\"> **Modified Code:** add batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_accuracy(logits,x_data,y_data):\n",
    "    \n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "    y_true_cls = tf.argmax(y, dimension=1)\n",
    "\n",
    "    prediction = tf.equal(y_pred_cls, y_true_cls)    \n",
    "    \n",
    "    num_examples = len(x_data)\n",
    "    batch_size = 8192\n",
    "    all_predictions = []\n",
    "    \n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = x_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "        all_predictions.extend(sess.run(prediction, feed_dict = {x: batch_x, y: batch_y}))    \n",
    "    \n",
    "    return np.mean(all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the computational graph using the defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "x_2d = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "conv_1_out = convolutional_layer(x_2d, 5, 1, 32, [1, 1, 1, 1], [1, 2, 2, 1], [1, 2, 2, 1])\n",
    "conv_2_out = convolutional_layer(conv_1_out, 5, 32, 64, [1, 1, 1, 1], [1, 2, 2, 1], [1, 2, 2, 1])\n",
    "\n",
    "layer_flat, num_features = flatten_layer(conv_2_out)\n",
    "\n",
    "layer_1 = fully_connected_layer(layer_flat, num_features, 512)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "logits = fully_connected_layer(layer_1, 512, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/modified.png\"> **Modified Code:** change the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits,y)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/old.png\"> **Create the session and initialize the variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img align=\"left\" src=\"files/old.png\"> **Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(1000, xtr, ytr, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"files/old.png\"> **Test accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620727272727273"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(logits,xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95530000000000004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(logits,xte,yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95599999999999996"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(logits,xva,yva)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
